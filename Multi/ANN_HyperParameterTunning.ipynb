{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6531b6aa-929b-4254-bcee-1f88bd4c0628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Arfan Shah\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de7e2031-e369-4558-be85-6947ebc879d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Red_Mean</th>\n",
       "      <th>Red_Median</th>\n",
       "      <th>Red_Variance</th>\n",
       "      <th>Red_Std</th>\n",
       "      <th>Green_Mean</th>\n",
       "      <th>Green_Median</th>\n",
       "      <th>Green_Variance</th>\n",
       "      <th>Green_Std</th>\n",
       "      <th>Blue_Mean</th>\n",
       "      <th>Blue_Median</th>\n",
       "      <th>Blue_Variance</th>\n",
       "      <th>Blue_Std</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121.849594</td>\n",
       "      <td>145.0</td>\n",
       "      <td>3304.497718</td>\n",
       "      <td>57.484761</td>\n",
       "      <td>125.967102</td>\n",
       "      <td>135.0</td>\n",
       "      <td>1763.033006</td>\n",
       "      <td>41.988487</td>\n",
       "      <td>111.251572</td>\n",
       "      <td>134.0</td>\n",
       "      <td>3330.577657</td>\n",
       "      <td>57.711157</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103.830032</td>\n",
       "      <td>102.0</td>\n",
       "      <td>2152.241390</td>\n",
       "      <td>46.392256</td>\n",
       "      <td>114.606018</td>\n",
       "      <td>121.0</td>\n",
       "      <td>1838.561514</td>\n",
       "      <td>42.878450</td>\n",
       "      <td>95.103455</td>\n",
       "      <td>88.0</td>\n",
       "      <td>3073.705972</td>\n",
       "      <td>55.441013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116.047089</td>\n",
       "      <td>134.0</td>\n",
       "      <td>2488.556041</td>\n",
       "      <td>49.885429</td>\n",
       "      <td>119.544250</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1193.293666</td>\n",
       "      <td>34.544083</td>\n",
       "      <td>100.909332</td>\n",
       "      <td>119.0</td>\n",
       "      <td>2621.018971</td>\n",
       "      <td>51.195888</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>136.331741</td>\n",
       "      <td>139.0</td>\n",
       "      <td>1649.347666</td>\n",
       "      <td>40.612162</td>\n",
       "      <td>147.529755</td>\n",
       "      <td>151.0</td>\n",
       "      <td>1412.353454</td>\n",
       "      <td>37.581291</td>\n",
       "      <td>126.857681</td>\n",
       "      <td>129.0</td>\n",
       "      <td>2512.158838</td>\n",
       "      <td>50.121441</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>129.850250</td>\n",
       "      <td>134.0</td>\n",
       "      <td>1940.935613</td>\n",
       "      <td>44.056051</td>\n",
       "      <td>131.718399</td>\n",
       "      <td>139.0</td>\n",
       "      <td>1782.426972</td>\n",
       "      <td>42.218799</td>\n",
       "      <td>101.312119</td>\n",
       "      <td>94.0</td>\n",
       "      <td>2798.758005</td>\n",
       "      <td>52.903289</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Red_Mean  Red_Median  Red_Variance    Red_Std  Green_Mean  Green_Median  \\\n",
       "0  121.849594       145.0   3304.497718  57.484761  125.967102         135.0   \n",
       "1  103.830032       102.0   2152.241390  46.392256  114.606018         121.0   \n",
       "2  116.047089       134.0   2488.556041  49.885429  119.544250         125.0   \n",
       "3  136.331741       139.0   1649.347666  40.612162  147.529755         151.0   \n",
       "4  129.850250       134.0   1940.935613  44.056051  131.718399         139.0   \n",
       "\n",
       "   Green_Variance  Green_Std   Blue_Mean  Blue_Median  Blue_Variance  \\\n",
       "0     1763.033006  41.988487  111.251572        134.0    3330.577657   \n",
       "1     1838.561514  42.878450   95.103455         88.0    3073.705972   \n",
       "2     1193.293666  34.544083  100.909332        119.0    2621.018971   \n",
       "3     1412.353454  37.581291  126.857681        129.0    2512.158838   \n",
       "4     1782.426972  42.218799  101.312119         94.0    2798.758005   \n",
       "\n",
       "    Blue_Std  label  \n",
       "0  57.711157      0  \n",
       "1  55.441013      1  \n",
       "2  51.195888      0  \n",
       "3  50.121441      1  \n",
       "4  52.903289      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load and read dataset\n",
    "dataset = pd.read_excel('final_dataset.xlsx')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86d8739a-6079-4473-a9b1-1319c05281f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    0\n",
       "3    1\n",
       "4    1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate dataset into dependent and independent sets\n",
    "x = dataset.iloc[:, :-1]\n",
    "y = dataset.iloc[:, -1]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b5a2116-4f1d-4170-9b0c-ac43b78c89b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.23500032,  0.42004827,  1.22358984, ...,  0.69557054,\n",
       "         0.52964155,  0.57699777],\n",
       "       [-1.07910805, -1.23470125, -0.25989263, ..., -1.1143668 ,\n",
       "         0.21483548,  0.28083278],\n",
       "       [-0.50681269, -0.00325975,  0.1730986 , ...,  0.10537358,\n",
       "        -0.33994975, -0.27299009],\n",
       "       ...,\n",
       "       [ 0.13847124,  0.15067044,  0.22896819, ...,  0.26275944,\n",
       "         0.22765812,  0.29313266],\n",
       "       [-1.74647231, -1.54256162, -1.5399771 , ..., -1.07502033,\n",
       "        -1.67287985, -1.84339441],\n",
       "       [-0.2624165 , -0.31112012, -1.30148167, ..., -0.1307052 ,\n",
       "        -1.07766581, -1.0899189 ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scale the values\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb142a75-8b65-4367-ab09-5d1d1e868201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into training and testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67249c81-910c-4e46-b815-05d729fd65cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Arfan Shah\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 12)                156       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               1664      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 35231 (137.62 KB)\n",
      "Trainable params: 35231 (137.62 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# prepare model\n",
    "model = Sequential()\n",
    "\n",
    "# input layer for ann\n",
    "model.add(Dense(units = 12, input_dim = 12, input_shape = (12, ), kernel_initializer = 'uniform'))\n",
    "\n",
    "# first hidden layer\n",
    "model.add(Dense(units = 128, activation = 'relu', kernel_initializer = 'uniform'))\n",
    "\n",
    "# second hidden layer\n",
    "model.add(Dense(units = 128, activation = 'tanh', kernel_initializer = 'uniform'))\n",
    "\n",
    "# third hidden layer\n",
    "model.add(Dense(units = 128, activation = 'relu', kernel_initializer = 'uniform'))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(units = 3, activation = 'softmax', kernel_initializer = 'uniform'))\n",
    "\n",
    "# summary for model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "386de695-adfb-4977-b7c3-fc16582ca2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Arfan Shah\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer = 'adam', loss = 'SparseCategoricalCrossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "264e3bf7-2e28-49b8-bbf5-876eaae0303d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\Arfan Shah\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Arfan Shah\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "229/229 [==============================] - 4s 4ms/step - loss: 0.6747 - accuracy: 0.7139\n",
      "Epoch 2/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.2667 - accuracy: 0.9156\n",
      "Epoch 3/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.2092 - accuracy: 0.9292\n",
      "Epoch 4/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.1600 - accuracy: 0.9371\n",
      "Epoch 5/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.1365 - accuracy: 0.9478\n",
      "Epoch 6/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.1269 - accuracy: 0.9546\n",
      "Epoch 7/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.1083 - accuracy: 0.9619\n",
      "Epoch 8/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.1001 - accuracy: 0.9640\n",
      "Epoch 9/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0947 - accuracy: 0.9656\n",
      "Epoch 10/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0956 - accuracy: 0.9634\n",
      "Epoch 11/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.0893 - accuracy: 0.9665\n",
      "Epoch 12/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.0852 - accuracy: 0.9689\n",
      "Epoch 13/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.0796 - accuracy: 0.9684\n",
      "Epoch 14/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.0801 - accuracy: 0.9700\n",
      "Epoch 15/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.0775 - accuracy: 0.9724\n",
      "Epoch 16/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.0725 - accuracy: 0.9715\n",
      "Epoch 17/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.0691 - accuracy: 0.9741\n",
      "Epoch 18/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.1075 - accuracy: 0.9649\n",
      "Epoch 19/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.0685 - accuracy: 0.9726\n",
      "Epoch 20/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.0636 - accuracy: 0.9768\n",
      "Epoch 21/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.0638 - accuracy: 0.9754\n",
      "Epoch 22/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.0690 - accuracy: 0.9730\n",
      "Epoch 23/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.0620 - accuracy: 0.9746\n",
      "Epoch 24/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0592 - accuracy: 0.9781\n",
      "Epoch 25/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0583 - accuracy: 0.9805\n",
      "Epoch 26/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0538 - accuracy: 0.9787\n",
      "Epoch 27/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0554 - accuracy: 0.9790\n",
      "Epoch 28/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0525 - accuracy: 0.9807\n",
      "Epoch 29/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0467 - accuracy: 0.9825\n",
      "Epoch 30/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0462 - accuracy: 0.9849\n",
      "Epoch 31/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0578 - accuracy: 0.9792\n",
      "Epoch 32/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0439 - accuracy: 0.9816\n",
      "Epoch 33/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0529 - accuracy: 0.9800\n",
      "Epoch 34/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0440 - accuracy: 0.9831\n",
      "Epoch 35/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0432 - accuracy: 0.9838\n",
      "Epoch 36/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0352 - accuracy: 0.9866\n",
      "Epoch 37/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0371 - accuracy: 0.9873\n",
      "Epoch 38/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0388 - accuracy: 0.9864\n",
      "Epoch 39/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0343 - accuracy: 0.9860\n",
      "Epoch 40/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0475 - accuracy: 0.9809\n",
      "Epoch 41/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0305 - accuracy: 0.9888\n",
      "Epoch 42/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0338 - accuracy: 0.9877\n",
      "Epoch 43/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0360 - accuracy: 0.9857\n",
      "Epoch 44/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0321 - accuracy: 0.9868\n",
      "Epoch 45/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0322 - accuracy: 0.9866\n",
      "Epoch 46/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0326 - accuracy: 0.9873\n",
      "Epoch 47/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0304 - accuracy: 0.9895\n",
      "Epoch 48/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0226 - accuracy: 0.9921\n",
      "Epoch 49/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0238 - accuracy: 0.9908\n",
      "Epoch 50/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0286 - accuracy: 0.9888\n",
      "Epoch 51/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.0356 - accuracy: 0.9875\n",
      "Epoch 52/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0420 - accuracy: 0.9866\n",
      "Epoch 53/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0279 - accuracy: 0.9906\n",
      "Epoch 54/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0286 - accuracy: 0.9888\n",
      "Epoch 55/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0222 - accuracy: 0.9908\n",
      "Epoch 56/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0220 - accuracy: 0.9932\n",
      "Epoch 57/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0181 - accuracy: 0.9930\n",
      "Epoch 58/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0240 - accuracy: 0.9904\n",
      "Epoch 59/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0276 - accuracy: 0.9888\n",
      "Epoch 60/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0210 - accuracy: 0.9917\n",
      "Epoch 61/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0295 - accuracy: 0.9901\n",
      "Epoch 62/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0216 - accuracy: 0.9912\n",
      "Epoch 63/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0154 - accuracy: 0.9941\n",
      "Epoch 64/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0168 - accuracy: 0.9934\n",
      "Epoch 65/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0187 - accuracy: 0.9921\n",
      "Epoch 66/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0292 - accuracy: 0.9884\n",
      "Epoch 67/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0164 - accuracy: 0.9941\n",
      "Epoch 68/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0294 - accuracy: 0.9901\n",
      "Epoch 69/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0260 - accuracy: 0.9908\n",
      "Epoch 70/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0147 - accuracy: 0.9952\n",
      "Epoch 71/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0127 - accuracy: 0.9952\n",
      "Epoch 72/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0093 - accuracy: 0.9967\n",
      "Epoch 73/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0329 - accuracy: 0.9886\n",
      "Epoch 74/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0238 - accuracy: 0.9917\n",
      "Epoch 75/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0258 - accuracy: 0.9906\n",
      "Epoch 76/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.0138 - accuracy: 0.9958\n",
      "Epoch 77/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.0093 - accuracy: 0.9969\n",
      "Epoch 78/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.0134 - accuracy: 0.9947\n",
      "Epoch 79/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.0228 - accuracy: 0.9910\n",
      "Epoch 80/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.0102 - accuracy: 0.9961\n",
      "Epoch 81/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.0169 - accuracy: 0.9941\n",
      "Epoch 82/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.0267 - accuracy: 0.9908\n",
      "Epoch 83/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.0175 - accuracy: 0.9934\n",
      "Epoch 84/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.0116 - accuracy: 0.9958\n",
      "Epoch 85/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.0145 - accuracy: 0.9952\n",
      "Epoch 86/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.0111 - accuracy: 0.9963\n",
      "Epoch 87/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.0150 - accuracy: 0.9958\n",
      "Epoch 88/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.0047 - accuracy: 0.9985\n",
      "Epoch 89/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.0130 - accuracy: 0.9958\n",
      "Epoch 90/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.0244 - accuracy: 0.9917\n",
      "Epoch 91/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.0176 - accuracy: 0.9945\n",
      "Epoch 92/100\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0194 - accuracy: 0.9923\n",
      "Epoch 93/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.0281 - accuracy: 0.9923\n",
      "Epoch 94/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.0062 - accuracy: 0.9989\n",
      "Epoch 95/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9980\n",
      "Epoch 96/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.0077 - accuracy: 0.9971\n",
      "Epoch 97/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.0187 - accuracy: 0.9932\n",
      "Epoch 98/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.0205 - accuracy: 0.9941\n",
      "Epoch 99/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.0109 - accuracy: 0.9969\n",
      "Epoch 100/100\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.0131 - accuracy: 0.9963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1e6935a1e10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "model.fit(x_train, y_train, epochs = 100, batch_size = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1008db7-ea38-453b-8546-541121c11b0e",
   "metadata": {},
   "source": [
    "# Hyperparameter Tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09161830-cdc7-42e3-a214-794603108589",
   "metadata": {},
   "source": [
    "### Tuning Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0e1f151-6ba0-4eba-ab6f-44d14c53b291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select appropriate optimizer by hyperparameter tuning\n",
    "def build_model(hp):\n",
    "    model1 = Sequential()\n",
    "\n",
    "    model1.add(Dense(units = 12, input_dim = 12, input_shape = (12, ), kernel_initializer = 'uniform'))\n",
    "    model1.add(Dense(units = 128, activation = 'relu', kernel_initializer = 'uniform'))\n",
    "    model1.add(Dense(units = 128, activation = 'tanh', kernel_initializer = 'uniform'))\n",
    "    model1.add(Dense(units = 128, activation = 'relu', kernel_initializer = 'uniform'))\n",
    "    model1.add(Dense(units = 3, activation = 'softmax', kernel_initializer = 'uniform'))\n",
    "\n",
    "    optimizer = hp.Choice('optimizer', values = ['adam', 'rmsprop', 'adadelta', 'SGD', 'adamw'])\n",
    "\n",
    "    model1.compile(optimizer = optimizer, loss = 'SparseCategoricalCrossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e213ffb-f5c9-48d0-bfbe-598d9ba8d634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now make a tuner object\n",
    "tuner = kt.RandomSearch(build_model, objective = 'val_accuracy', max_trials = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e5811a6-700f-45cd-ac13-9c3361e1e9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 00s]\n",
      "\n",
      "Best val_accuracy So Far: 0.9631901979446411\n",
      "Total elapsed time: 00h 00m 40s\n"
     ]
    }
   ],
   "source": [
    "# now search for the best optimizer\n",
    "tuner.search(x_train, y_train, epochs = 10, validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "151043b2-8f2a-47bf-89e8-62ce54b51155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer': 'adam'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now find the best optimizer\n",
    "tuner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f765a98-69e9-4e0a-beb3-ce81b13731c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch best model\n",
    "model2 = tuner.get_best_models(num_models = 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8ac04c1-9c48-4eef-87c7-1d8220962686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 12)                156       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               1664      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 35231 (137.62 KB)\n",
      "Trainable params: 35231 (137.62 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f925a692-7981-449f-83cd-680a1c81c581",
   "metadata": {},
   "source": [
    "### Tuning Number of Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c07ad403-afe6-4173-9cd5-75c3a9cf563b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning number of neurons\n",
    "def no_neurons(hp):\n",
    "\n",
    "    # initiate model\n",
    "    model = Sequential()\n",
    "\n",
    "    # range of no of neurons\n",
    "    unit = hp.Int('unit', min_value = 12, max_value = 128, step = 8)\n",
    "\n",
    "    # input layer\n",
    "    model.add(Dense(units = 12, input_dim = 12, input_shape = (12, ), kernel_initializer = 'uniform'))\n",
    "\n",
    "    # first hidden layer\n",
    "    model.add(Dense(units = unit, activation = 'relu', kernel_initializer = 'uniform'))\n",
    "\n",
    "    # second hidden layer\n",
    "    model.add(Dense(units = unit, activation = 'tanh', kernel_initializer = 'uniform'))\n",
    "\n",
    "    # third hidden layer\n",
    "    model.add(Dense(units = unit, activation = 'relu', kernel_initializer = 'uniform'))\n",
    "\n",
    "    model.compile(optimizer = 'adam', loss = 'SparseCategoricalCrossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bef08af8-718d-40bb-99d3-4f7c89916185",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner1 = kt.RandomSearch(no_neurons, objective = 'val_accuracy', max_trials = 16, directory = 'Arfan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20b43102-567b-4565-bd53-908550a9f325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15 Complete [00h 00m 06s]\n",
      "val_accuracy: 0.9070990085601807\n",
      "\n",
      "Best val_accuracy So Far: 0.945661723613739\n",
      "Total elapsed time: 00h 01m 35s\n"
     ]
    }
   ],
   "source": [
    "tuner1.search(x_train, y_train, epochs = 5, validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "951063ae-ec37-410b-8048-1a9d1a75aba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unit': 108}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner1.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cfa4dfe7-25e6-4b9f-b887-d76fcf24e699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 12)                156       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               1300      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21656 (84.59 KB)\n",
      "Trainable params: 21656 (84.59 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model12 = tuner1.get_best_models(num_models = 1)[0]\n",
    "model12.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bd30f8-017f-4bb9-92e5-ed2ee5381de9",
   "metadata": {},
   "source": [
    "### Tuning Number of Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8bf0dc0-0976-4b41-b3a2-6a08f54f674c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_layers(hp):\n",
    "    model22 = Sequential()\n",
    "\n",
    "    # input layer\n",
    "    model22.add(Dense(units = 12, input_dim = 12, input_shape = (12, ), kernel_initializer = 'uniform'))\n",
    "\n",
    "    # apply for loop to get exact number of hidden layers\n",
    "    for i in range(hp.Int('num_layers', min_value = 1, max_value = 10)):\n",
    "        model22.add(Dense(units = 108, activation = 'relu', kernel_initializer = 'uniform'))\n",
    "    model22.add(Dense(units = 3, activation = 'softmax', kernel_initializer = 'uniform'))\n",
    "\n",
    "    # compile\n",
    "    model22.compile(optimizer = 'adam', loss = 'SparseCategoricalCrossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    return model22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f783442-c532-420d-9146-6095a0fd588e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner22 = kt.RandomSearch(num_layers, objective = 'val_accuracy',  max_trials = 10, directory = 'tuner22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4c3eb98-431c-4c10-9627-c483df9445b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 05s]\n",
      "val_accuracy: 0.32953548431396484\n",
      "\n",
      "Best val_accuracy So Far: 0.9465381503105164\n",
      "Total elapsed time: 00h 00m 35s\n"
     ]
    }
   ],
   "source": [
    "tuner22.search(x_train, y_train, epochs = 5, validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3d5f214-4087-4199-94cc-864f7f215680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_layers': 3}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner22.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "13a4f7b5-36ff-48ad-b53c-4987123355dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 12)                156       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 108)               1404      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 108)               11772     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 108)               11772     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 3)                 327       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25431 (99.34 KB)\n",
      "Trainable params: 25431 (99.34 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modell = tuner22.get_best_models(num_models = 1)[0]\n",
    "modell.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35030fd8-a71b-4f5c-b22a-3ad12915b0f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
