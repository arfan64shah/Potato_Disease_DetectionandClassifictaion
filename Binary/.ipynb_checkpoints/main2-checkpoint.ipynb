{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb15eb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the required libraries\n",
    "import skimage.feature as skf\n",
    "import openpyxl\n",
    "import numpy as np\n",
    "import math\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "from scipy.stats import skew, kurtosis\n",
    "import skimage.feature\n",
    "import xlsxwriter\n",
    "import os\n",
    "\n",
    "\n",
    "#creates general file for features of all the three channels\n",
    "outWorkbook = xlsxwriter.Workbook(\"Output30.xlsx\")\n",
    "outSheet = outWorkbook.add_worksheet()\n",
    "\n",
    "#Writes headers for general file \n",
    "outSheet.write(\"A1\", \"Mean_R\")\n",
    "outSheet.write(\"B1\", \"RMS_R\")\n",
    "outSheet.write(\"C1\", \"Median_R\")\n",
    "outSheet.write(\"D1\", \"Variance_R\")\n",
    "outSheet.write(\"E1\", \"Std_R\")\n",
    "outSheet.write(\"F1\", \"Skewness_R\")\n",
    "outSheet.write(\"G1\", \"Kurtosis_R\")\n",
    "outSheet.write(\"H1\", \"Contrast_R\")\n",
    "outSheet.write(\"I1\", \"Entropy_R\")\n",
    "outSheet.write(\"J1\", \"Energy_R\")\n",
    "outSheet.write(\"K1\", \"Homogeneity_R\")\n",
    "outSheet.write(\"L1\", \"Correlation_R\")\n",
    "outSheet.write(\"M1\", \"IDM_R\")\n",
    "outSheet.write(\"N1\", \"Smoothness_R\")\n",
    "outSheet.write(\"O1\", \"Mean_G\")\n",
    "outSheet.write(\"P1\", \"RMS_G\")\n",
    "outSheet.write(\"Q1\", \"Median_G\")\n",
    "outSheet.write(\"R1\", \"Variance_G\")\n",
    "outSheet.write(\"S1\", \"Std_G\")\n",
    "outSheet.write(\"T1\", \"Skewness_G\")\n",
    "outSheet.write(\"U1\", \"Kurtosis_G\")\n",
    "outSheet.write(\"V1\", \"Contrast_G\")\n",
    "outSheet.write(\"W1\", \"Entropy_G\")\n",
    "outSheet.write(\"X1\", \"Energy_G\")\n",
    "outSheet.write(\"Y1\", \"Homogeneity_G\")\n",
    "outSheet.write(\"Z1\", \"Correlation_G\")\n",
    "outSheet.write(\"AA1\", \"IDM_G\")\n",
    "outSheet.write(\"AB1\", \"Smoothness_G\")\n",
    "outSheet.write(\"AC1\", \"Mean_B\")\n",
    "outSheet.write(\"AD1\", \"RMS_B\")\n",
    "outSheet.write(\"AE1\", \"Median_B\")\n",
    "outSheet.write(\"AF1\", \"Variance_B\")\n",
    "outSheet.write(\"AG1\", \"Std_B\")\n",
    "outSheet.write(\"AH1\", \"Skewness_B\")\n",
    "outSheet.write(\"AI1\", \"Kurtosis_B\")\n",
    "outSheet.write(\"AJ1\", \"Contrast_B\")\n",
    "outSheet.write(\"AK1\", \"Entropy_B\")\n",
    "outSheet.write(\"AL1\", \"Energy_B\")\n",
    "outSheet.write(\"AM1\", \"Homogeneity_B\")\n",
    "outSheet.write(\"AN1\", \"Correlation_B\")\n",
    "outSheet.write(\"AO1\", \"IDM_B\")\n",
    "outSheet.write(\"AP1\", \"Smoothness_B\")\n",
    "outWorkbook.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d06b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a file for red channel\n",
    "outWorkbookR = xlsxwriter.Workbook(\"RedChannel30.xlsx\")\n",
    "outSheetR = outWorkbookR.add_worksheet()\n",
    "\n",
    "#writes headers for red file\n",
    "outSheetR.write(\"A1\", \"Mean_R\")\n",
    "outSheetR.write(\"B1\", \"RMS_R\")\n",
    "outSheetR.write(\"C1\", \"Median_R\")\n",
    "outSheetR.write(\"D1\", \"Variance_R\")\n",
    "outSheetR.write(\"E1\", \"Std_R\")\n",
    "outSheetR.write(\"F1\", \"Skewness_R\")\n",
    "outSheetR.write(\"G1\", \"Kurtosis_R\")\n",
    "outSheetR.write(\"H1\", \"Contrast_R\")\n",
    "outSheetR.write(\"I1\", \"Entropy_R\")\n",
    "outSheetR.write(\"J1\", \"Energy_R\")\n",
    "outSheetR.write(\"K1\", \"Homogeneity_R\")\n",
    "outSheetR.write(\"L1\", \"Correlation_R\")\n",
    "outSheetR.write(\"M1\", \"IDM_R\")\n",
    "outSheetR.write(\"N1\", \"Smoothness_R\")\n",
    "outWorkbookR.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63500d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates file for green channel\n",
    "outWorkbookG = xlsxwriter.Workbook(\"GreenChannel30.xlsx\")\n",
    "outSheetG = outWorkbookG.add_worksheet()\n",
    "\n",
    "#writes headers for green file\n",
    "outSheetG.write(\"A1\", \"Mean_G\")\n",
    "outSheetG.write(\"B1\", \"RMS_G\")\n",
    "outSheetG.write(\"C1\", \"Median_G\")\n",
    "outSheetG.write(\"D1\", \"Variance_G\")\n",
    "outSheetG.write(\"E1\", \"Std_G\")\n",
    "outSheetG.write(\"F1\", \"Skewness_G\")\n",
    "outSheetG.write(\"G1\", \"Kurtosis_G\")\n",
    "outSheetG.write(\"H1\", \"Contrast_G\")\n",
    "outSheetG.write(\"I1\", \"Entropy_G\")\n",
    "outSheetG.write(\"J1\", \"Energy_G\")\n",
    "outSheetG.write(\"K1\", \"Homogeneity_G\")\n",
    "outSheetG.write(\"L1\", \"Correlation_G\")\n",
    "outSheetG.write(\"M1\", \"IDM_G\")\n",
    "outSheetG.write(\"N1\", \"Smoothness_G\")\n",
    "outWorkbookG.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a7133a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a file for blue channel\n",
    "outWorkbookB = xlsxwriter.Workbook(\"BlueChannel30.xlsx\")\n",
    "outSheetB = outWorkbookB.add_worksheet()\n",
    "\n",
    "#writes headers for blue file\n",
    "outSheetB.write(\"A1\", \"Mean_B\")\n",
    "outSheetB.write(\"B1\", \"RMS_B\")\n",
    "outSheetB.write(\"C1\", \"Median_B\")\n",
    "outSheetB.write(\"D1\", \"Variance_B\")\n",
    "outSheetB.write(\"E1\", \"Std_B\")\n",
    "outSheetB.write(\"F1\", \"Skewness_B\")\n",
    "outSheetB.write(\"G1\", \"Kurtosis_B\")\n",
    "outSheetB.write(\"H1\", \"Contrast_B\")\n",
    "outSheetB.write(\"I1\", \"Entropy_B\")\n",
    "outSheetB.write(\"J1\", \"Energy_B\")\n",
    "outSheetB.write(\"K1\", \"Homogeneity_B\")\n",
    "outSheetB.write(\"L1\", \"Correlation_B\")\n",
    "outSheetB.write(\"M1\", \"IDM_B\")\n",
    "outSheetB.write(\"N1\", \"Smoothness_B\")\n",
    "outWorkbookB.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e57238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob\n",
    "# import os\n",
    "# import cv2\n",
    "# from PIL import Image\n",
    "# import numpy as np\n",
    "\n",
    "# directory = r'/home/uca/Desktop/Undergrad/Arfan_FinalYearProject/10_Data/processed_30'\n",
    "# os.makedirs(directory, exist_ok=True)  # create the directory if it does not exist\n",
    "\n",
    "# for filename in glob.glob('/home/uca/Desktop/Undergrad/Arfan_FinalYearProject/10_Data/data30/*.*'):\n",
    "#     im = cv2.imread(filename)\n",
    "    \n",
    "#     # Convert the image to grayscale\n",
    "#     image = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    \n",
    "#     # apply mean filter\n",
    "#     # convert to HSV\n",
    "#     image = cv2.cvtColor(im, cv2.COLOR_BGR2HSV)\n",
    "#     image = cv2.blur(image, (5, 5))\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_HSV2RGB)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     # Apply laplacian filter to reduce the affects of mean filter which has blurred edges\n",
    "#     # Apply the Laplacian filter to enhance the edges\n",
    "#     laplacian = cv2.Laplacian(image, cv2.CV_64F)\n",
    "#     # Adjust the contrast of the Laplacian image\n",
    "#     laplacian = cv2.convertScaleAbs(laplacian)\n",
    "#     # Add the Laplacian image back to the original to create the final enhanced image\n",
    "#     image = cv2.addWeighted(im, 1.5, laplacian, -0.5, 0)\n",
    "    \n",
    "    \n",
    "#     # Convert the image to a NumPy array\n",
    "#     image_array = np.array(image)\n",
    "#     # Invert the colors\n",
    "#     inverted_array = 255 - image_array   \n",
    "#     # Convert the NumPy array back to an image\n",
    "#     image = Image.fromarray(inverted_array.astype(np.uint8))\n",
    "    \n",
    "    \n",
    "#     file = os.path.basename(filename)\n",
    "#     image_array = np.array(image, dtype=np.uint8) # convert the Image object to a NumPy array of type uint8\n",
    "#     cv2.imwrite(os.path.join(directory, file), image_array) # save the image in the created directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5820d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "directory = r'/home/uca/Desktop/Undergrad/Arfan_FinalYearProject/10_Data/processed_30'\n",
    "os.makedirs(directory, exist_ok=True)  # create the directory if it does not exist\n",
    "\n",
    "for filename in glob.glob('/home/uca/Desktop/Undergrad/Arfan_FinalYearProject/10_Data/data30/*.*'):\n",
    "    im = cv2.imread(filename)\n",
    "    \n",
    "    # Convert the image to grayscale\n",
    "    image = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # apply mean filter\n",
    "    # convert to HSV\n",
    "    image = cv2.cvtColor(im, cv2.COLOR_BGR2HSV)\n",
    "    image = cv2.blur(image, (5, 5))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_HSV2RGB)\n",
    "    \n",
    "    # Apply laplacian filter to reduce the affects of mean filter which has blurred edges\n",
    "    # Apply the Laplacian filter to enhance the edges\n",
    "    laplacian = cv2.Laplacian(image, cv2.CV_64F)\n",
    "    # Adjust the contrast of the Laplacian image\n",
    "    laplacian = cv2.convertScaleAbs(laplacian)\n",
    "    # Add the Laplacian image back to the original to create the final enhanced image\n",
    "    image = cv2.addWeighted(im, 1.5, laplacian, -0.5, 0)\n",
    "    \n",
    "    # Convert the image to a NumPy array\n",
    "    image_array = np.array(image)\n",
    "    # Invert the colors\n",
    "    inverted_array = 255 - image_array   \n",
    "    # Convert the NumPy array back to an image\n",
    "    image = Image.fromarray(inverted_array.astype(np.uint8))\n",
    "    \n",
    "    # Convert the image to grayscale\n",
    "    image = cv2.cvtColor(np.array(image), cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # apply otsu segmentation\n",
    "    # apply adaptive thresholding to obtain a binary image\n",
    "    thresh = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 25, 2)\n",
    "\n",
    "    # perform morphological opening to remove small objects and smooth edges\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))\n",
    "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # find contours in the image\n",
    "    contours, hierarchy = cv2.findContours(opening, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # create a mask for the infected parts of the leaf\n",
    "    mask = np.zeros_like(opening)\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area > 1000:\n",
    "            cv2.drawContours(mask, [cnt], 0, 255, -1)\n",
    "\n",
    "    # apply the mask to the original image\n",
    "    image = cv2.bitwise_and(im, im, mask=mask)\n",
    "    \n",
    "    file = os.path.basename(filename)\n",
    "    image_array = np.array(image, dtype=np.uint8) # convert the Image object to a NumPy array of type uint8\n",
    "    cv2.imwrite(os.path.join(directory, file), image_array) # save the image in the created directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce471ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libaray to read and make a list of all the needy images\n",
    "import glob\n",
    "\n",
    "#declare an empty list\n",
    "Image_list = []\n",
    "\n",
    "#using for loop to append to the list declared above\n",
    "for filename in glob.glob('/home/uca/Desktop/Undergrad/Arfan_FinalYearProject/10_Data/processed_30/*.*'):\n",
    "    im = Image.open(filename)\n",
    "    \n",
    "    #append each image to the list declared above\n",
    "    Image_list.append(im)\n",
    "    \n",
    "#prints number of images used\n",
    "print(len(Image_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9526ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uses for loop to read each image and array of each image\n",
    "for i in range(0, len(Image_list)):\n",
    "    Image = Image_list[i]\n",
    "    im = asarray(Image)\n",
    "  \n",
    "    \n",
    "    #Here i am extracting the single channel like red, green, and blue from the whole image array\n",
    "    R = image[:, :, 0]\n",
    "    G = image[:, :, 1]\n",
    "    B = image[:, :, 2]\n",
    "\n",
    "\n",
    "    #selecting features from Red Channel\n",
    "    print(\"Calculating Statistical features for Red Channel: \")\n",
    "    \n",
    "    #calculates mean\n",
    "    Mean_R = np.mean(R);\n",
    "    print(Mean_R)\n",
    "    \n",
    "    #calculating root mean square\n",
    "    RMS_R = np.sqrt(np.mean(R**2))\n",
    "    print(RMS_R)\n",
    "    \n",
    "    #calculating median\n",
    "    Median_R = np.median(R)\n",
    "    print(Median_R)\n",
    "    \n",
    "    #calculating variance of the pixels\n",
    "    Variance_R = np.var(R)\n",
    "    print(Variance_R)\n",
    "    \n",
    "    #calculating standard deviation\n",
    "    Std_R = math.sqrt(Variance_R)\n",
    "    print(Std_R)\n",
    "    \n",
    "    #calculates skewness\n",
    "    Skewness_R = skew(R.reshape(-1))\n",
    "    print(Skewness_R)\n",
    "    \n",
    "    #calculates kurtosis\n",
    "    Kurtosis_R = kurtosis(R.reshape(-1))\n",
    "    print(Kurtosis_R)\n",
    "    \n",
    "    #calculates entropy\n",
    "    Entropy_R = skimage.measure.shannon_entropy(R)\n",
    "    print(Entropy_R)\n",
    "    \n",
    "    #returns an image array where lowest pixel value is 0 and highest 8 instead of 0 and 255\n",
    "    R = skimage.img_as_ubyte(R)\n",
    "    \n",
    "    #calculates contrast\n",
    "    g1 = skf.graycomatrix(R, [1], [0], levels=256, symmetric=False, normed=True)\n",
    "    Contrast_R = skf.graycoprops(g1, 'contrast')[0][0]\n",
    "    print(Contrast_R)\n",
    "    \n",
    "    #calculates energy\n",
    "    Energy_R = skf.graycoprops(g1, 'energy')[0][0]\n",
    "    print(Energy_R)\n",
    "    \n",
    "    #calculating homogeniety\n",
    "    Homogeneity_R = skf.graycoprops(g1, 'homogeneity')[0][0]\n",
    "    print(Homogeneity_R)\n",
    "    \n",
    "    #finding correlation\n",
    "    Correlation_R = skf.graycoprops(g1, 'correlation')[0][0]\n",
    "    print(Correlation_R)\n",
    "    \n",
    "    #glcm_R = skf.graycomatrix(R, distances=[1], angles=[0], levels=256, symmetric= False, normed=True)\n",
    "    \n",
    "    #calculate inverse difference moment (IDM)\n",
    "    IDM_R = 1 / (1 + Contrast_R - Energy_R)\n",
    "    print(IDM_R)\n",
    "    \n",
    "    #calculates smoothness\n",
    "    diff_R = np.diff(R.astype(float))\n",
    "    variance_R = np.var(diff_R)\n",
    "    Smoothness_R = variance_R / (R.shape[0] * R.shape[1])\n",
    "    print(Smoothness_R)\n",
    "    \n",
    "\n",
    "    #selecting features from Green Channel\n",
    "    print(\"Calculating Statistical Features for Green Channel: \")\n",
    "    \n",
    "    #calculates mean\n",
    "    Mean_G = np.mean(G);\n",
    "    print(Mean_G)\n",
    "    \n",
    "    #calculates root mean square\n",
    "    RMS_G = np.sqrt(np.mean(G**2))\n",
    "    print(RMS_G)\n",
    "    \n",
    "    #calculates median\n",
    "    Median_G = np.median(G)\n",
    "    print(Median_G)\n",
    "    \n",
    "    #claculates variance\n",
    "    Variance_G = np.var(G)\n",
    "    print(Variance_G)\n",
    "    \n",
    "    #calculates standard deviation\n",
    "    Std_G = math.sqrt(Variance_G)\n",
    "    print(Std_G)\n",
    "    \n",
    "    #calculates skewness\n",
    "    Skewness_G = skew(G.reshape(-1))\n",
    "    print(Skewness_G)\n",
    "    \n",
    "    #calculates kurtosis\n",
    "    Kurtosis_G = kurtosis(G.reshape(-1))\n",
    "    print(Kurtosis_G)\n",
    "    \n",
    "    #calculates entropy\n",
    "    Entropy_G = skimage.measure.shannon_entropy(G)\n",
    "    print(Entropy_G)\n",
    "    \n",
    "    #converts images pixels to range of 0 to 8 instead of 0 to 255\n",
    "    G = skimage.img_as_ubyte(G)\n",
    "    \n",
    "    #calculates contrast\n",
    "    g2 = skf.graycomatrix(G, [1], [0], levels=256, symmetric=False, normed=True)\n",
    "    Contrast_G = skf.graycoprops(g2, 'contrast')[0][0]\n",
    "    print(Contrast_G)\n",
    "    \n",
    "    #calculates energy\n",
    "    Energy_G = skf.graycoprops(g2, 'energy')[0][0]\n",
    "    print(Energy_G)\n",
    "    \n",
    "    #calculates homogeniety\n",
    "    Homogeneity_G = skf.graycoprops(g2, 'homogeneity')[0][0]\n",
    "    print(Homogeneity_G)\n",
    "    \n",
    "    #calculates correlation\n",
    "    Correlation_G = skf.graycoprops(g2, 'correlation')[0][0]\n",
    "    print(Correlation_G)\n",
    "    #glcm_G = skf.graycomatrix(G, distances=[1], angles=[0], levels=256, symmetric=True, normed=True)\n",
    "    \n",
    "    #calculates inverse difference moment (IDM)\n",
    "    IDM_G = 1 / (1 + Contrast_G - Energy_G)\n",
    "    print(IDM_G)\n",
    "    \n",
    "    #calculates smoothness\n",
    "    diff_G = np.diff(G.astype(float))\n",
    "    variance_G = np.var(diff_G)\n",
    "    Smoothness_G = variance_G / (G.shape[0] * G.shape[1])\n",
    "    print(Smoothness_G)\n",
    "\n",
    "    #selecting features from Blue Channel\n",
    "    print(\"Calculating Statistical Features for Blue Channel: \")\n",
    "    \n",
    "    #calculates mean\n",
    "    Mean_B = np.mean(B);\n",
    "    print(Mean_B)\n",
    "    \n",
    "    #calculates root mean square\n",
    "    RMS_B = np.sqrt(np.mean(B**2))\n",
    "    print(RMS_B)\n",
    "    \n",
    "    #calculates median\n",
    "    Median_B = np.median(B)\n",
    "    print(Median_B)\n",
    "    \n",
    "    #calculates variance\n",
    "    Variance_B = np.var(B)\n",
    "    print(Variance_B)\n",
    "    \n",
    "    #calculates standard deviation\n",
    "    Std_B = math.sqrt(Variance_B)\n",
    "    print(Std_B)\n",
    "    \n",
    "    #calculates skewness\n",
    "    Skewness_B = skew(B.reshape(-1))\n",
    "    print(Skewness_B)\n",
    "    \n",
    "    #calculates kurtosis\n",
    "    Kurtosis_B = kurtosis(B.reshape(-1))\n",
    "    print(Kurtosis_B)\n",
    "    \n",
    "    #calculates entropy\n",
    "    Entropy_B = skimage.measure.shannon_entropy(B)\n",
    "    print(Entropy_B)\n",
    "    \n",
    "    #converts range of pixels values from 0-255 to 0-8\n",
    "    B = skimage.img_as_ubyte(B)\n",
    "    \n",
    "    #calculates contrast\n",
    "    g3 = skf.graycomatrix(B, [1], [0], levels=256, symmetric=False, normed=True)\n",
    "    Contrast_B = skf.graycoprops(g3, 'contrast')[0][0]\n",
    "    print(Contrast_B)\n",
    "    \n",
    "    #calculates energy\n",
    "    Energy_B = skf.graycoprops(g3, 'energy')[0][0]\n",
    "    print(Energy_B)\n",
    "    \n",
    "    #calculates homogeniety\n",
    "    Homogeneity_B = skf.graycoprops(g3, 'homogeneity')[0][0]\n",
    "    print(Homogeneity_B)\n",
    "    \n",
    "    #calculates correlation\n",
    "    Correlation_B = skf.graycoprops(g3, 'correlation')[0][0]\n",
    "    print(Correlation_B)\n",
    "    \n",
    "    #glcm_B = skf.graycomatrix(B, distances=[1], angles=[0], levels=256, symmetric=True, normed=True)\n",
    "    \n",
    "    #calculates inverse difference moment (IDM)\n",
    "    IDM_B = 1 / (1 + Contrast_B - Energy_B)\n",
    "    print(IDM_B)\n",
    "    \n",
    "    #calculates smoothness\n",
    "    diff_B = np.diff(B.astype(float))\n",
    "    variance_B = np.var(diff_B)\n",
    "    Smoothness_B = variance_B / (B.shape[0] * B.shape[1])\n",
    "    print(Smoothness_B)\n",
    "    \n",
    "    #count the number of images\n",
    "    print(\"Image number: \", i)\n",
    "\n",
    "\n",
    "    #Declares data for all the three channels\n",
    "    values_R = [Mean_R, RMS_R, Median_R, Variance_R, Std_R, Skewness_R, Kurtosis_R, Entropy_R, Contrast_R, Energy_R, Homogeneity_R, Correlation_R, IDM_R, Smoothness_R]\n",
    "    values_G = [Mean_G, RMS_G, Median_G, Variance_G, Std_G, Skewness_G, Kurtosis_G, Entropy_G, Contrast_G, Energy_G, Homogeneity_G, Correlation_G, IDM_G, Smoothness_G]\n",
    "    values_B = [Mean_B, RMS_B, Median_B, Variance_B, Std_B, Skewness_B, Kurtosis_B, Entropy_B, Contrast_B, Energy_B, Homogeneity_B, Correlation_B, IDM_B, Smoothness_B]\n",
    "\n",
    "    #Writes red channels into a file\n",
    "    outWorkbookR = openpyxl.load_workbook(\"RedChannel30.xlsx\")\n",
    "    outSheetR = outWorkbookR.active\n",
    "    outSheetR.append(values_R)\n",
    "    outWorkbookR.save(filename=\"RedChannel30.xlsx\")\n",
    "\n",
    "    #Writes green channels into a file\n",
    "    outWorkbookG = openpyxl.load_workbook(\"GreenChannel30.xlsx\")\n",
    "    outSheetG = outWorkbookG.active\n",
    "    outSheetG.append(values_G)\n",
    "    outWorkbookG.save(filename=\"GreenChannel30.xlsx\")\n",
    "\n",
    "    #writes blue chanels into a file\n",
    "    outWorkbookB = openpyxl.load_workbook(\"BlueChannel30.xlsx\")\n",
    "    outSheetB = outWorkbookB.active\n",
    "    outSheetB.append(values_B)\n",
    "    outWorkbookB.save(filename=\"BlueChannel30.xlsx\")\n",
    "    \n",
    "    #creates a general fle where all the three channels data will be merged\n",
    "    outWorkbook = xlsxwriter.Workbook(\"Output30.xlsx\")\n",
    "    outSheet = outWorkbook.add_worksheet()\n",
    "        \n",
    "    #declares data for general file\n",
    "    values = [Mean_R, RMS_R, Median_R, Variance_R, Std_R, Skewness_R, Kurtosis_R, Entropy_R, Contrast_R, Energy_R, Homogeneity_R, Correlation_R, IDM_R, Smoothness_R, Mean_G, RMS_G, Median_R, Variance_G, Std_G, Skewness_G, Kurtosis_G, Entropy_G, Contrast_G, Energy_G, Homogeneity_G, Correlation_G, IDM_G, Smoothness_G, Mean_B, RMS_B, Median_R, Variance_B, Std_B, Skewness_B, Kurtosis_B, Entropy_B, Contrast_B, Energy_B, Homogeneity_B, Correlation_B, IDM_B, Smoothness_B]\n",
    "    \n",
    "     \n",
    "    #writes into the general file\n",
    "    outWorkbook = openpyxl.load_workbook(\"Output30.xlsx\") \n",
    "    outSheet = outWorkbook.active\n",
    "    outSheet.append(values)\n",
    "    \n",
    "    #here the general file is being saved\n",
    "    outWorkbook.save(filename=\"Output30.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5ebc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the specific channels to csv data\n",
    "import pandas as pd\n",
    "#Convert red channel\n",
    "red_file = pd.read_excel('RedChannel30.xlsx')\n",
    "red_file.to_csv('RedData30.csv')\n",
    "\n",
    "#Convert green channel\n",
    "green_file = pd.read_excel('GreenChannel30.xlsx')\n",
    "green_file.to_csv('GreenData30.csv')\n",
    "\n",
    "#Convert blue channel\n",
    "blue_file = pd.read_excel('BlueChannel30.xlsx')\n",
    "blue_file.to_csv('BlueData30.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f123f11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the main file which contains features of all the three channels into csv\n",
    "file = pd.read_excel('Output30.xlsx')\n",
    "file.to_csv('Output30.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4e8546",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d27627",
   "metadata": {},
   "source": [
    "## Apply SVM on Red Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44da9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #read the data\n",
    "# redData = pd.read_csv('RedData.csv')\n",
    "# labelled = pd.read_csv('Labels1.csv')\n",
    "\n",
    "# #classify data into dependent and indepedent variables\n",
    "# redX = redData.iloc[:, :]\n",
    "# redY = labelled.iloc[:, :]\n",
    "\n",
    "# #classify the data into training and testing\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# redx_train, redx_test, redy_train, redy_test = train_test_split(redX, redY, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# #now predict using svm classifier\n",
    "# from sklearn.svm import SVC\n",
    "# redSVC = SVC()\n",
    "\n",
    "# #fit the model\n",
    "# redSVC.fit(redx_train, redy_train)\n",
    "# pred_r = redSVC.predict(redx_test)\n",
    "\n",
    "# #lets now find the accuracy\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# print(\"The accuracy for red Channel is \", accuracy_score(redy_test, pred_r))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fece39d9",
   "metadata": {},
   "source": [
    "## Apply SVM on Green Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a1f8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #read the data\n",
    "# greenData = pd.read_csv('GreenData.csv')\n",
    "\n",
    "# #classify data into dependent and indepedent variables\n",
    "# greenX = greenData.iloc[:, :]\n",
    "# greenY = labelled.iloc[:, :]\n",
    "\n",
    "# #classify the data into training and testing\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# greenx_train, greenx_test, greeny_train, greeny_test = train_test_split(greenX, greenY, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# #now predict using svm classifier\n",
    "# from sklearn.svm import SVC\n",
    "# greenSVC = SVC()\n",
    "\n",
    "# #fit the model\n",
    "# greenSVC.fit(greenx_train, greeny_train)\n",
    "# pred_g = greenSVC.predict(greenx_test)\n",
    "\n",
    "# #lets now find the accuracy\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# print(\"The accuracy for green Channel is \", accuracy_score(greeny_test, pred_g))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01887332",
   "metadata": {},
   "source": [
    "## Apply SVM on Blue Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d46c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #read the data\n",
    "# blueData = pd.read_csv('BlueData.csv')\n",
    "\n",
    "# #classify data into dependent and indepedent variables\n",
    "# blueX = blueData.iloc[:, :]\n",
    "# blueY = labelled.iloc[:, :]\n",
    "\n",
    "# #classify the data into training and testing\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# bluex_train, bluex_test, bluey_train, bluey_test = train_test_split(blueX, blueY, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# #now predict using svm classifier\n",
    "# from sklearn.svm import SVC\n",
    "# blueSVC = SVC()\n",
    "\n",
    "# #fit the model\n",
    "# blueSVC.fit(bluex_train, bluey_train)\n",
    "# pred_b = blueSVC.predict(bluex_test)\n",
    "\n",
    "# #lets now find the accuracy\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# print(\"The accuracy for red Channel is \", accuracy_score(bluey_test, pred_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ef1184",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5968871",
   "metadata": {},
   "source": [
    "## Apply Random Forest on red channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8da685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #read the data\n",
    "# RedData = pd.read_csv('RedData.csv')\n",
    "# labelled = pd.read_csv('Labels1.csv')\n",
    "\n",
    "# #classify data into dependent and indepedent variables\n",
    "# RedX = RedData.iloc[:, :]\n",
    "# RedY = labelled.iloc[:, :]\n",
    "\n",
    "# #classify the data into training and testing\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# Redx_train, Redx_test, Redy_train, Redy_test = train_test_split(RedX, RedY, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# #now predict using svm classifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# RedRF = RandomForestClassifier()\n",
    "\n",
    "# #fit the model\n",
    "# RedRF.fit(Redx_train, Redy_train)\n",
    "# pred_R = RedRF.predict(Redx_test)\n",
    "\n",
    "# #lets now find the accuracy\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# print(\"The accuracy for red Channel is \", accuracy_score(Redy_test, pred_R))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11680822",
   "metadata": {},
   "source": [
    "## Apply Random Forest on green channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f851d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #read the data\n",
    "# GreenData = pd.read_csv('GreenData.csv')\n",
    "\n",
    "# #classify data into dependent and indepedent variables\n",
    "# GreenX = GreenData.iloc[:, :]\n",
    "# GreenY = labelled.iloc[:, :]\n",
    "\n",
    "# #classify the data into training and testing\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# Greenx_train, Greenx_test, Greeny_train, Greeny_test = train_test_split(GreenX, GreenY, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# #now predict using svm classifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# GreenRF = RandomForestClassifier()\n",
    "\n",
    "# #fit the model\n",
    "# GreenRF.fit(Greenx_train, Greeny_train)\n",
    "# pred_G = GreenRF.predict(Greenx_test)\n",
    "\n",
    "# #lets now find the accuracy\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# print(\"The accuracy for green Channel is \", accuracy_score(Greeny_test, pred_G))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e811ab42",
   "metadata": {},
   "source": [
    "## Apply Random Forest on blue channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3a5c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #read the data\n",
    "# BlueData = pd.read_csv('BlueData.csv')\n",
    "\n",
    "# #classify data into dependent and indepedent variables\n",
    "# BlueX = BlueData.iloc[:, :]\n",
    "# BlueY = labelled.iloc[:, :]\n",
    "\n",
    "# #classify the data into training and testing\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# Bluex_train, Bluex_test, Bluey_train, Bluey_test = train_test_split(BlueX, BlueY, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# #now predict using svm classifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# BlueRF = RandomForestClassifier()\n",
    "\n",
    "# #fit the model\n",
    "# BlueRF.fit(Bluex_train, Bluey_train)\n",
    "# pred_B = BlueRF.predict(Bluex_test)\n",
    "\n",
    "# #lets now find the accuracy\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# print(\"The accuracy for red Channel is \", accuracy_score(Bluey_test, pred_B))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
